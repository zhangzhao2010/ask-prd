我在做一个名为ASK-PRD的项目，主要功能是为产品经理提供基于PRD的智能检索和问答。


## 场景举例
产品经理会有一堆的PRD（产品需求文档）文件（PDF），每个文档中都包含当前版本的需求迭代信息，文档为图文混排的，图片可能是流程图，原型图，脑图等。
经过多个版本的积累，某些产品功能和特性可能做了多次变更，当有新人加入时，想了解这些产品迭代的历史是比较费力的，所以需要一个智能检索和生成的机器人，来帮助产品经理快速检索和理解产品迭代的相关信息。

例如，用户输入信息：『xx APP的注册登录方式的演进是怎样的？』，机器人会检索到所有相关的PRD，阅读这些文档，然后总结出相关信息，回复给用户。


## 系统设计
整个项目主要分为两个部分：KnowledgeBase Builder 和 Agentic Robot。
* 『KnowledgeBase Builder』部分主要是解析PRD文档，转化为文本和向量，存储到向量数据库中；
* 『Agentic Robot』部分主要是根据用户的输入来检索文档，阅读文档，生成回答；

### KnowledgeBase Builder 设计
1. 所有 PRD 文档会以 PDF 的格式存储在 S3；
2. 运行Builder，会将所有pdf下载到本地；
3. 使用 datalab-to/marker这个项目，将PDF转为markdown+image；
4. 将markdown和image传给Claude 4进行多模态的理解，转化为markdown + text（图片描述）的文档；
5. 将文本文档分chunk转化为向量，存储到向量数据库；

### Agentic Robot 设计
1. 接收用户输入的问题（query）；
2. 根据用户输入检索向量数据库，拿到相关的chunk信息和文档元数据（可以重写用户的输入以实现更好的检索效果）；
3. 下载检索到的文档到本地（markdown+image）；
4. 使用sub-agent来完成单个文档的阅读和总结，每个文档启动一个sub-agent，将markdown和图片联合用户的输入都传给大模型，让大模型总结文档核心内容，输出回复+引用；
5. Main agent收集sub-agent的返回，总结输出最终结果+引用；


## 技术设计
- 整个项目基于 AWS 相关服务构建
- 向量数据库使用 Amazon OpenSearch Serverless
- 项目做成前后端分离，前端使用Nextjs(样式使用Cloudscape)，后端使用Python FastAPI
- 第一版应用部署先使用单一EC2
- 交互中的存储都使用sqllite存储到本地，例如创建知识库后的知识库的元数据，用户查询记录等
- embedding模型和大模型服务都是用AWS Bedrock上的模型


## 交互设计&页面设计
- 知识库管理页面 - 知识库列表
  - 列出所有知识库
- 知识库管理页面 - 创建知识库
  - 点击『创建知识库』按钮，弹出表单，输入知识库名称，描述，指定S3存储地址（桶和路径），创建数据库；
  - 在 Amazon OpenSearch Serverless 中建立 collection；
  - 元数据存储到本地数据库；
- 文档管理页面 - 文档列表
  - 下拉框选择知识库，列出当前知识库所有文档
- 文档管理页面 - 上传文档
  - 下拉框选择知识库，点击『上传文档』，选择对应的可以上传本地文档到对应的S3桶；
- 文档管理页面 - 数据同步
  - 点击『数据同步』按钮，触发『数据同步逻辑』
- 文档管理页面 - 删除文档
  - 下拉框选择知识库，列出当前知识库所有文档，勾选文档，点击『删除』按钮，可以删除对应文档，同时此文档关联的相关数据也应被删除
- 检索&问答页面 - 提问
  - 此页面设计可以参考perplexity，用户在搜索框输入问题，点击按钮提交问题，后端Agent收到问题后执行『文档检索生成逻辑』，返回生成的答案以及引用的文档
  

## 核心业务逻辑设计

### 数据同步逻辑

原始PDF文件上传至S3后，需经过一系列处理才能进入向量数据库，流程如下：
1. 每个PDF都被转化为markdown文档加图片，每个文档放到一个单独文件夹存储，目录要跟源文件的目录分离开来；
2. 将上一步中得到的每张图片传给大模型进行理解(可以从markdown文件中找到图片对应的上下文)，得到详细的图片描述，然后将图片描述和markdown做整合，形成一份纯文本的markdown文件；
3. 将上一步中得到的纯文本的markdown文件分chunk，然后向量化，然后把相应数据（包括向量数据和元数据）存储到向量数据库；
4. 数据同步逻辑完成；

### 文档检索生成逻辑

1. 这是一个 Agentic 程序；
2. agent接收用户输入（query）；
3. 使用大模型重写用户输入，以提高召回准确率；
4. 检索向量数据库，得到相应的chunk和相关元数据；
5. 从元数据中得到markdown文件（markdown+图片）（可能是多个文件）；
6. 针对每个markdown文件，启动一个sub-agent执行以下逻辑：
    1. 下载markdown文件到本地；
    2. 将markdown文件内容和用户输入（query）组合成大模型的输入；
    3. 大模型需要生成以下内容：文档结构概要；针对用户输入的回答；引用的文档块；
    4. 生成的内容返回给主agent；
7. 主agent拿到sub-agent的返回后，调用大模型针对用户的问题进行回答，回复内容包括：问题的回答和引用的文档块（可能是文字块，也可能是图片）；
8. 页面展示回复和引用；


## 其它文档
* `maker.md`:  datalab-to/marker readme文档


---
---
请根据以上信息和我讨论完善这个项目的需求文档和设计文档